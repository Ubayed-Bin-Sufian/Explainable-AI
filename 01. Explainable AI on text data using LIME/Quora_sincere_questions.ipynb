{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        " <h1> <center> <b> Explainable AI on text data using LIME </b> </center> </h1> \n",
        " \n",
        "  This code is sourced from https://www.youtube.com/watch?v=-9HYGAoZbnc"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0yhTxD60crmq"
      },
      "source": [
        "Install LIME"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_etbfiSzg6Gy",
        "outputId": "f321b5ec-bf00-437e-846c-350a77bc8d7f"
      },
      "outputs": [],
      "source": [
        "pip install lime"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-3pERlamcuMI"
      },
      "source": [
        "Import packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hMS-tbB7g106"
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from lime.lime_text import LimeTextExplainer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from collections import OrderedDict"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6iLfJ_Tocv69"
      },
      "source": [
        "Load training data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "J3FjV8Tlg107",
        "outputId": "8e9b4284-e4f0-4c3e-84a3-f7ed91e2d809"
      },
      "outputs": [],
      "source": [
        "# Load training data\n",
        "# Link of the dataset: https://www.kaggle.com/c/quora-insincere-questions-classification\n",
        "train_df = pd.read_csv(\"/content/data/train.csv\")\n",
        "print(\"Train shape : \", train_df.shape)\n",
        "print(train_df.head)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZH0Nsc6kgmWY"
      },
      "source": [
        "Display rows with NaN values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cewnXmF0QnuA",
        "outputId": "271d6cf9-889b-4d57-99d1-553cf12e35e7"
      },
      "outputs": [],
      "source": [
        "# Display rows with NaN (Not a Number) values\n",
        "nan_rows = train_df[train_df.isna().any(axis=1)]\n",
        "print(nan_rows)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q44voEFvgsCl"
      },
      "source": [
        "Print train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EIwW3OGpQxkZ",
        "outputId": "054cbf37-697f-4020-a634-64b866d23c98"
      },
      "outputs": [],
      "source": [
        "# Remove rows with NaN values\n",
        "train_df = train_df.dropna()\n",
        "print(\"Train shape : \", train_df.shape)\n",
        "print(train_df.head)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KUdQBSkNgxKr"
      },
      "source": [
        "Train and val data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o6tS4MkPO-Gy"
      },
      "outputs": [],
      "source": [
        "# Split the data into training and validation sets\n",
        "# test_size=0.1: 10% of the data will be used for the validation set (val_df), and the remaining 90% will be used for the training set (train_df).\n",
        "# random_state=2018: This ensures reproducibility. By setting a random seed, the split will be the same every time the code is run.\n",
        "train_df, val_df = train_test_split(train_df, test_size=0.1, random_state=2018)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mDMkYnmSmQWx",
        "outputId": "d28be60a-c0de-44d1-8bbc-351cf4949ca9"
      },
      "outputs": [],
      "source": [
        "print(val_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0uAPZuNGg2qs"
      },
      "source": [
        "Select sample val data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0gOyQQWFO-Gy"
      },
      "outputs": [],
      "source": [
        "# Select specific rows from validation set based on qid for inspection\n",
        "df_select = pd.concat([val_df[val_df['qid'] == '0e1ef5fd2470e01ece3d'], val_df[val_df['qid'] == '1397322310ad2a880150']], axis=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RexVFtabg7Qg"
      },
      "source": [
        "Select question"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VN9SnlxWO-Gz",
        "outputId": "ed165f1c-b44d-462c-f4d6-b2ec216ebde2"
      },
      "outputs": [],
      "source": [
        "# Display the 'question_text' column of selected rows\n",
        "df_select.question_text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8W8NwTVLhDPp"
      },
      "source": [
        "Print val data head"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "15qfs5eRO-Gz",
        "outputId": "79681afb-fb5d-4512-aedb-c82964121d88"
      },
      "outputs": [],
      "source": [
        "# Reset index of validation dataframe; validation dataset starts with 0\n",
        "val_df.reset_index(drop=True, inplace=True)\n",
        "print(val_df)\n",
        "\n",
        "# If we observe the no. of rows in val_df and compare with train_df. val_df is 10% of train_df."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bIaP59ofhGm2"
      },
      "source": [
        "<b> TF-IDF vectorizer </b>\n",
        "\n",
        "TF-IDF: Term Frequency-Inverse Document Frequency <br>\n",
        "\n",
        "The TF-IDF vectorizer is a tool used in text processing and natural language processing (NLP) to convert text data into numerical form so that machine learning models can use it. <br>\n",
        "\n",
        "What is TF-IDF?\n",
        "- Term Frequency (TF): Measures how often a word appears in a document. If a word appears frequently in a document, it gets a higher score.\n",
        "- Inverse Document Frequency (IDF): Measures how important a word is. Words that appear in many documents (like common words \"the\", \"is\", etc.) get a lower score because they are less unique. <br>\n",
        "\n",
        "By using TF-IDF, we can effectively filter out common words that don't carry much meaning (like \"and\", \"the\", \"is\") and focus on the important terms that really define the content of each document. This makes it a powerful tool for text analysis and machine learning applications involving text data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KDJWt2d_O-Gz"
      },
      "outputs": [],
      "source": [
        "# Create a TF-IDF vectorizer and transform the training and validation data\n",
        "\n",
        "## vectorize to tf-idf vectors\n",
        "tfidf_vc = TfidfVectorizer(min_df = 10, max_features = 100000, analyzer = \"word\", ngram_range = (1, 2), stop_words = 'english', lowercase = True)\n",
        "train_vc = tfidf_vc.fit_transform(train_df[\"question_text\"])\n",
        "val_vc = tfidf_vc.transform(val_df[\"question_text\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uJVYD-KAhIvQ"
      },
      "source": [
        "Logistic regression model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8BGMgTcVO-Gz"
      },
      "outputs": [],
      "source": [
        "# Train a Logistic Regression model on the training data\n",
        "model = LogisticRegression(C = 0.5, solver = \"sag\")\n",
        "model = model.fit(train_vc, train_df.target)\n",
        "\n",
        "# Predict on the validation data\n",
        "val_pred = model.predict(val_vc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DUvupHKfhzhG"
      },
      "source": [
        "Evaluation metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qjNvZTg9Sxdd"
      },
      "outputs": [],
      "source": [
        "# Calculate evaluation metrics\n",
        "# A module that provides tools to evaluate the performance of machine learning models\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
        "\n",
        "accuracy = accuracy_score(val_df.target, val_pred)\n",
        "precision = precision_score(val_df.target, val_pred)\n",
        "recall = recall_score(val_df.target, val_pred)\n",
        "f1 = f1_score(val_df.target, val_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TbqjtuMfS6yQ",
        "outputId": "b7fb4cff-064e-4f72-abc0-08d5dee9d1b3"
      },
      "outputs": [],
      "source": [
        "# Print evaluation metrics\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"F1 Score:\", f1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<b> Confusion Matrix </b>\n",
        "\n",
        "The confusion matrix is a 2x2 matrix for binary classification problems, showing the counts of true positives, true negatives, false positives, and false negatives.\n",
        "\n",
        "<b> Confusion Matrix Breakdown </b>\n",
        "\n",
        "For a binary classification problem, the confusion matrix typically looks like this:\n",
        "\n",
        "<table border=\"1\" style=\"border-collapse: collapse;\">\n",
        "  <tr>\n",
        "    <th></th>\n",
        "    <th>Predicted Negative</th>  \n",
        "    <th>Predicted Positive</th>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td>Actual Negative</td>\n",
        "    <td>True Negative (TN)</td>\n",
        "    <td>False Positive (FP)</td>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td>Actual Positive</td>\n",
        "    <td>False Negative (FN)</td>\n",
        "    <td>True Positive (TP)</td>\n",
        "  </tr>\n",
        "</table>\n",
        "\n",
        "- True Negative (TN): The model correctly predicted the negative class.\n",
        "- False Positive (FP): The model incorrectly predicted the positive class (Type I error).\n",
        "- False Negative (FN): The model incorrectly predicted the negative class (Type II error).\n",
        "- True Positive (TP): The model correctly predicted the positive class."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eOTSNAfOS-NI",
        "outputId": "62199433-ce67-47ed-b533-bacd91a14d31"
      },
      "outputs": [],
      "source": [
        "# Display confusion matrix\n",
        "conf_matrix = confusion_matrix(val_df.target, val_pred)\n",
        "print(\"Confusion Matrix:\\n\", conf_matrix)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ky-C1p_vTAQc",
        "outputId": "280360db-941e-46e8-875d-028677d340c6"
      },
      "outputs": [],
      "source": [
        "# Display classification report\n",
        "# Define class names\n",
        "class_names = [\"sincere\", \"insincere\"]\n",
        "class_report = classification_report(val_df.target, val_pred, target_names=class_names)\n",
        "print(\"Classification Report:\\n\", class_report)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SgcvMupFUye0",
        "outputId": "334e92b2-a589-4f78-a597-9bf756268e5d"
      },
      "outputs": [],
      "source": [
        "# Filter the rows where target is 1\n",
        "target_1_rows = val_df[val_df['target'] == 1]\n",
        "\n",
        "# Print the filtered rows and their row indices\n",
        "print(\"Rows with target = 1:\")\n",
        "print(target_1_rows)\n",
        "\n",
        "print(\"\\nRow indices of rows with target = 1:\")\n",
        "print(target_1_rows.index.tolist())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uv_CZKmuO-Gz",
        "outputId": "caa1630c-0558-496a-a7b7-d5a4a79f3f24"
      },
      "outputs": [],
      "source": [
        "# Select a specific instance from the validation set for explanation\n",
        "import numpy as np\n",
        "prediction_index = 20\n",
        "idx = int(val_df.index[prediction_index])\n",
        "# print(idx)\n",
        "c = make_pipeline(tfidf_vc, model)\n",
        "class_names = [\"sincere\", \"insincere\"]\n",
        "\n",
        "# Create a LIME text explainer\n",
        "explainer = LimeTextExplainer(class_names = class_names)\n",
        "\n",
        "# Explain the prediction for the selected instance\n",
        "exp = explainer.explain_instance(val_df[\"question_text\"][idx], c.predict_proba, num_features = 10)\n",
        "\n",
        "# Print the selected question text and its prediction probabilities\n",
        "print(val_df[\"question_text\"][idx])\n",
        "print(\"Probability (Insincere) =\", c.predict_proba([val_df[\"question_text\"][idx]])[0, 1])\n",
        "print(\"Probability (Sincere) =\", c.predict_proba([val_df[\"question_text\"][idx]])[0, 0])\n",
        "print(\"True Class is:\", class_names[int(val_df[\"target\"][idx])])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "apbnR46hO-G0",
        "outputId": "30d1d050-0df9-4ba3-94e7-07bf6aaed581"
      },
      "outputs": [],
      "source": [
        "# Get explanation weights as a list of tuples\n",
        "exp.as_list()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JT4uzRSDO-G0"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CcTjWm0tO-G0",
        "outputId": "e181871a-e867-4083-fb45-2c0248003e14"
      },
      "outputs": [],
      "source": [
        "# Print original prediction probability\n",
        "print('Original prediction:',  model.predict_proba(val_vc[prediction_index])[0, 1])\n",
        "\n",
        "# Create a copy of the selected instance's TF-IDF vector and modify specific features\n",
        "tmp = val_vc[prediction_index].copy()\n",
        "tmp[0, tfidf_vc.vocabulary_['indians']] = 0\n",
        "tmp[0, tfidf_vc.vocabulary_['europeans']] = 0\n",
        "\n",
        "# Print prediction after removing specific features\n",
        "print('Prediction after removing some features:', model.predict_proba(tmp)[0, 1])\n",
        "\n",
        "# Print the difference in prediction probabilities\n",
        "print('Difference:', model.predict_proba(tmp)[0, 1] - model.predict_proba(val_vc[prediction_index])[0, 1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 331
        },
        "id": "xZc7vJUQO-G0",
        "outputId": "f4483a54-cc67-4b60-b565-82b4ff86e8f3"
      },
      "outputs": [],
      "source": [
        "# Display LIME explanation in a notebook\n",
        "exp.show_in_notebook(text=val_df[\"question_text\"][idx], labels=(1,))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 642
        },
        "id": "nOrOwD9jO-G0",
        "outputId": "2859e32c-3f0a-4022-ff15-100f107c89a2"
      },
      "outputs": [],
      "source": [
        "# Extract and plot LIME weights\n",
        "weights = OrderedDict(exp.as_list())\n",
        "lime_weights = pd.DataFrame({\"words\": list(weights.keys()), \"weights\": list(weights.values())})\n",
        "\n",
        "# Plot the feature weights\n",
        "sns.barplot(x = \"words\", y = \"weights\", data = lime_weights, palette=\"viridis\")\n",
        "plt.xticks(rotation = 45)\n",
        "plt.title(\"Sample {} features weights given by LIME\".format(idx))\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
